{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d602e0ee-11c3-4dc8-8b11-a1b764a75d6b",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Milestone 3 of reinforcement learning project. Notebook to get a GMRES that (1) works on GPU and (2) works with batched data.\n",
    "\n",
    "## TODO\n",
    "\n",
    "1. Finish testing.\n",
    "2. Setup dataset from other notebook.\n",
    "3. Integrate the GPU GMRES with the loss to see how much a single step will cost.\n",
    "4. Improve loss from Milestone 2.\n",
    "    1. Vectorize it.\n",
    "    2. Additional terms for sparsity?\n",
    "5. Begin to pretrain actor.\n",
    "    1. First experiment with models.\n",
    "        1. Minimize eye_dist.\n",
    "        2. Try different layers.\n",
    "        3. Try edge prediction. \n",
    "        4. REALLY TRY TO GET SPARSITY. (Log-sum penalty) ?\n",
    "    2. Anything that works, store in a python file.\n",
    "    3. Build out a python file that has models that have worked.\n",
    "    4. Make sure to save weights and successfully plots to /Weights and /Plots\n",
    "6. Train just on small (results).\n",
    "7. Train just on large (results).\n",
    "8. Train SMALLER -> freeze middle -> finetune on large.\n",
    "9. If SMALLER -> LARGER leads to shorter training times and >= results, include as a novelty presented in paper (like many PDE discretization techniques, it is common to control the size, we found results that suggest that the model can generalize well to smaller discretization spaces and be applied effectively to larger state spaces)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa0577-82ac-4284-b98c-ae00a1ba75e7",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Same helmholtz dataset from milestone 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ca998-fcad-40e9-ae16-c01323c74429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /data/users/jupyter-dam724/.local/lib/python3.9/site-packages/libpyg.so: undefined symbol: _ZN3c1010Dispatcher17runRecordFunctionERN2at14RecordFunctionESt17reference_wrapperIKNS_14FunctionSchemaEENS_11DispatchKeyE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(\n",
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spla\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7882a5a-fe31-4ee0-9398-f2f8d28bedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_helmholtz(n, density=0.1):\n",
    "    L = 1.0\n",
    "    k = np.random.uniform(1, 2)  # Random wavenumber\n",
    "    h = L / (n - 1)  \n",
    "\n",
    "    # Discretization of Helmholtz operator (1D)\n",
    "    diagonals = [np.ones(n-1), -2*np.ones(n), np.ones(n-1)]\n",
    "\n",
    "    helmholtz = sp.diags(diagonals, [-1, 0, 1]) / h**2 + k**2 * sp.eye(n)\n",
    "\n",
    "    # Ensure no perturbations on the tridiagnonal\n",
    "    perturb = sp.random(n, n, density=density) * np.max(helmholtz)\n",
    "    \n",
    "    perturb.setdiag(0)  # Main diagonal\n",
    "    perturb.setdiag(0, k=1)  # First upper diagonal\n",
    "    perturb.setdiag(0, k=-1)  # First lower diagonal\n",
    "        \n",
    "    return helmholtz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3dfb36-cfa2-4242-bfc7-f51ac64e2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_singularity(mat):\n",
    "    det_mat = np.linalg.det(mat)\n",
    "    print(det_mat)\n",
    "\n",
    "    if np.isclose(det_mat, 0):\n",
    "        print(\"Matrix is singular.\")\n",
    "        return False\n",
    "        \n",
    "    rank_mat = np.linalg.matrix_rank(mat)\n",
    "    if rank_mat < mat.shape[0]:\n",
    "        print(\"Matrix is singular.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"Matrix is non-singular.\")\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccbacf1-b35c-4991-9d2f-71e45b43e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(graph_data):\n",
    "    x_min = graph_data.min()\n",
    "    x_max = graph_data.max()\n",
    "    out = (graph_data - x_min) / (x_max - x_min + 1e-8)\n",
    "    return out.float()\n",
    "\n",
    "def normalize_edge_attr(graph_data):\n",
    "    e_min = graph_data.min()\n",
    "    e_max = graph_data.max()\n",
    "    out = (graph_data - e_min) / (e_max - e_min + 1e-8)\n",
    "    return out.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c216aa77-3dcc-4661-902a-e80b980cbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelmHoltzDataset(Dataset):\n",
    "    def __init__(self, generator, checker, norm_feat, norm_edge, epoch_len, size=20, density=0.1, transform=None):\n",
    "        super().__init__(None, transform)\n",
    "        \n",
    "        self.epoch_len = epoch_len\n",
    "        self.mat_size = size\n",
    "        self.mat_density = density\n",
    "        \n",
    "        self.generator = generator\n",
    "        self.checker = checker\n",
    "        \n",
    "        self.norm_features = norm_feat\n",
    "        self.norm_edge_attr = norm_edge\n",
    "\n",
    "    def len(self):\n",
    "        return self.epoch_len\n",
    "\n",
    "    def get(self, idx):\n",
    "        A = self.generator(self.mat_size, self.mat_density).toarray()\n",
    "        source_nodes, target_nodes = A.nonzero()\n",
    "        edge_weights = torch.from_numpy(A[source_nodes, target_nodes])\n",
    "        source_nodes = torch.from_numpy(source_nodes)\n",
    "        target_nodes = torch.from_numpy(target_nodes)\n",
    "        edge_index = torch.stack([source_nodes, target_nodes], dim=0).to(torch.int64)\n",
    "        \n",
    "        b = torch.randn(self.mat_size).unsqueeze(-1)\n",
    "        \n",
    "        node_features = self.norm_features(b)\n",
    "        edge_weights = self.norm_edge_attr(edge_weights)\n",
    "\n",
    "        data = Data(x=b, edge_index=edge_index, edge_attr=edge_weights)\n",
    "        return torch.from_numpy(A), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2aa68b-2272-463e-a6c4-47b7f81f6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HelmHoltzDataset(generate_random_helmholtz, test_singularity, normalize_features, normalize_edge_attr, 64*1000)\n",
    "vdataset = HelmHoltzDataset(generate_random_helmholtz, test_singularity, normalize_features, normalize_edge_attr, 64*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e31575-7465-4257-9f59-9bf5258d0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "vdataloader = DataLoader(vdataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f1249e-3a0e-4403-afbc-6df89420d884",
   "metadata": {},
   "source": [
    "## Loss Integration\n",
    "\n",
    "Identity distance from Milestone 2 (with vectorized form). This will be the form going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d6f6da-59d1-43f3-aac0-8c30d0914d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8fd2a9d-9158-41ed-8a00-1cdb6911b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdenittyDistance(nn.Module):\n",
    "    def __init__(self, l1=None, logsum=None):\n",
    "        super().__init__()\n",
    "        self.l1 = l1\n",
    "        self.logsum = logsum\n",
    "        self.size = 20\n",
    "        \n",
    "    def forward(self, inp, outp):\n",
    "        inp = inp.to(device, torch.float32)\n",
    "        avg_loss = 0\n",
    "        \n",
    "        batch_size = 1\n",
    "        identity = torch.eye(self.size, device=device).expand(batch_size, -1, -1)\n",
    "        inner_product = torch.bmm(outp.view(batch_size, self.size, self.size), inp.view(batch_size, self.size, self.size))\n",
    "        det = torch.mean(torch.abs(torch.linalg.det(inner_product))).item()\n",
    "        \n",
    "        # TODO : Pre-pre, idk man\n",
    "        \n",
    "        # Maximize the determinent | Minimize the condition number     \n",
    "        if False and det < 1.0:\n",
    "            slog_det = torch.log(torch.abs(torch.linalg.det(inner_product)))\n",
    "            avg_loss += -torch.mean(slog_det) * 1.0\n",
    "            \n",
    "        else:\n",
    "            #eye_frobenius_loss = torch.norm(inner_product - identity, p='fro', dim=(1, 2))\n",
    "            #avg_loss += torch.mean(eye_frobenius_loss) * 1.0\n",
    "        \n",
    "            singular_values = torch.linalg.svdvals(inner_product)\n",
    "            log_singular_values = torch.log(singular_values)\n",
    "            log_cond = log_singular_values.max(dim=1).values - log_singular_values.min(dim=1).values\n",
    "            avg_loss += torch.mean(log_cond) * 1.0\n",
    "        \n",
    "            if self.l1 is not None:\n",
    "                avg_loss += self.l1 * torch.norm(outp, p=1) * 1.0\n",
    "            elif self.logsum is not None:\n",
    "                avg_loss += torch.sum(torch.log(1 + torch.abs(outp) / self.logsum))\n",
    "        \n",
    "        return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fed77-e5d9-4eea-abd3-90576ba26071",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Potential models for actor network.\n",
    "\n",
    "**NOTE:** Aim for a model roughly 10 GBs in size. Need room for critic, actor, and GMRES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136ebae2-96aa-460c-abe8-86e8e3434fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as nn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f485930-2a6b-4b07-ba4a-578343b9cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_training_loop(epoches, criterion, train_loader, valid_loader, model, lr, b=None):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True, threshold=1e-3)\n",
    "\n",
    "    train_log, valid_log = np.zeros(epoches), np.zeros(epoches)\n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "        \n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        t_loader = tqdm(train_loader, desc=f'Train', leave=False, mininterval=2.0)\n",
    "        for batch in t_loader:\n",
    "            A, batch = batch\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            loss = criterion(A, output.to_dense())\n",
    "\n",
    "            t_loader.set_postfix(train_loss=loss.item())\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        valid_loss = 0\n",
    "        model.eval()\n",
    "        v_loader = tqdm(valid_loader, desc=f'Valid', leave=False, mininterval=2.0)\n",
    "        for batch in v_loader:\n",
    "            with torch.no_grad():\n",
    "                A, batch = batch\n",
    "                batch = batch.to(device)\n",
    "                output = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                loss = criterion(A, output.to_dense())\n",
    "\n",
    "                v_loader.set_postfix(valid_loss=loss.item())\n",
    "                valid_loss += loss.item()\n",
    "                \n",
    "        print(f'Epoch: {epoch}, Train: {train_loss/len(t_loader)}, Valid: {valid_loss/len(v_loader)}')\n",
    "        train_log[epoch], valid_log[epoch] = train_loss, valid_loss\n",
    "        \n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "    return train_log, valid_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fd21bc-a78e-4e00-9255-be684d08ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47d39a2e-d7f0-4612-82da-2649886dd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(train_log, valid_log, title='EX', filename='ex'):\n",
    "    plt.plot(train_log, label=\"Train\")\n",
    "    plt.plot(valid_log, label=\"Valid\")\n",
    "    plt.title(f'{title}: Train/Valid Log')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f'{filename}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb65c2-8d9d-4af3-8b30-733ddef0bca5",
   "metadata": {},
   "source": [
    "## (Edge Prediction) Models\n",
    "\n",
    "Models in which the node features are passed in pairs to linear layers and compute an edge weight.\n",
    "\n",
    "Sharing a training loop means some things like edge prediction will happen within the model class.\n",
    "\n",
    "This model fixes the sparsity to be exactly the same as the input by only computing entries on the edge indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00199b82-34b6-4938-8be9-0adfb2886de7",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Model from NeuralIF paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a8f4d3-822d-48a2-9aa8-859ee52c9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64138f2a-5d1a-41f5-b87a-880b5baa98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralIncompleteFactorization.neuralif import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a055c19a-775f-48fa-8a40-196efddb095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"latent_size\": 16, \n",
    "    \"message_passing_steps\": 4, \n",
    "    \"skip_connections\": 1,                  \n",
    "    \"augment_nodes\": 1, \n",
    "    \"global_features\": 0, \n",
    "    \"decode_nodes\": 4,                  \n",
    "    \"normalize_diag\": True, \n",
    "    \"activation\": True, \n",
    "    \"aggregate\": None, \n",
    "    \"graph_norm\": None,\n",
    "    \"two_hop\": None, \n",
    "    \"edge_features\": 4, \n",
    "    \"normalize\": None\n",
    "}\n",
    "\n",
    "model = models.NeuralPCG(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d884707-c08f-425d-a2b0-2940e9d3b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralIncompleteFactorization.apps import synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff35146-ce7f-471d-8b23-5b7a24288dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x58 and 1x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RL/precondition-discovery-contextual-bandit/neuralIncompleteFactorization/neuralif/models.py:209\u001b[0m, in \u001b[0;36mNeuralPCG.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    206\u001b[0m diag_idx \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    207\u001b[0m diag_values \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_attr[diag_idx]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 209\u001b[0m latent_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_edges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m latent_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_nodes(x_nodes)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message_passing_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage_passing:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/RL/precondition-discovery-contextual-bandit/neuralIncompleteFactorization/neuralif/models.py:128\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x58 and 1x16)"
     ]
    }
   ],
   "source": [
    "model(next(iter(dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c95a2-a760-4b78-8632-ca22a4b983b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be7877-6015-435d-9037-af8d21470de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a148202-db59-45d2-aee8-1e7a0d0338d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bcde470-e4bf-4f07-8272-53153f0e13d5",
   "metadata": {},
   "source": [
    "### TransformerConv\n",
    "\n",
    "Uses a transformer network to pass messages.\n",
    "\n",
    "This model is very broken. Some sort of index out of bounds, need to figure out where the issue is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fb517980-4e4f-47c9-af57-76e24107560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "d16eca1e-6f51-4183-93c2-a31dd69d1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import TransformerConv, GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "cd9afcdd-68d6-4579-8e46-4aa2be865166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=20, hidden_channels=128, heads=5, dropout=0.25, num_layers=5):\n",
    "        super(GraphTransformer, self).__init__()\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(GraphConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(GraphConv(hidden_channels, hidden_channels))\n",
    "        self.layers.append(GraphConv(hidden_channels, out_channels))\n",
    "        \n",
    "        self.edge_scorer = nn.Linear(2 * out_channels, 1)  \n",
    "\n",
    "    def forward(self, x_in, edge_index, edge_attr, batch):\n",
    "        x = x_in\n",
    "        for conv in self.layers:\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        # Compute edge scores\n",
    "        row, col = edge_index  # source and target node indices for each edge\n",
    "        edge_features = torch.cat([x[row], x[col]], dim=-1)  # Concatenate source and target embeddings\n",
    "        edge_scores = self.edge_scorer(edge_features).squeeze(-1)  # Shape: (num_edges,)\n",
    "        \n",
    "        # Initialize batched sparse matrices\n",
    "        num_nodes = 20\n",
    "        batch_size = batch.max().item() + 1\n",
    "        \n",
    "        # Select edges belonging to the i-th graph in the batch\n",
    "        batch_mask = (batch[row] == 0)\n",
    "        batch_edges = edge_index[:, batch_mask]\n",
    "        batch_scores = edge_scores[batch_mask]\n",
    "\n",
    "        # Create a sparse matrix for the i-th graph\n",
    "        sparse_matrix = torch.sparse_coo_tensor(\n",
    "            batch_edges,\n",
    "            batch_scores,\n",
    "            (num_nodes, num_nodes)\n",
    "        )\n",
    "                        \n",
    "        return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c9a18dfd-f7f5-4c57-bf61-eaf15cd90122",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtransformer = GraphTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c215029f-ac05-460f-a74c-8628fe1e8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 10\n",
    "loader = dataloader\n",
    "vloader = vdataloader\n",
    "model = gtransformer.to(device)\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "1127b7f9-f728-4615-abd8-a251a8fb5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = IdenittyDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6fee70e4-5b9f-43ac-ad9a-0bc3a7b15708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fa993f045e4ef88860a77051fcf190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/64000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[323], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_log, valid_log \u001b[38;5;241m=\u001b[39m \u001b[43mshared_training_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[314], line 15\u001b[0m, in \u001b[0;36mshared_training_loop\u001b[0;34m(epoches, criterion, train_loader, valid_loader, model, lr, b)\u001b[0m\n\u001b[1;32m     13\u001b[0m A, batch \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     14\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(A, output\u001b[38;5;241m.\u001b[39mto_dense())\n\u001b[1;32m     18\u001b[0m t_loader\u001b[38;5;241m.\u001b[39mset_postfix(train_loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[319], line 18\u001b[0m, in \u001b[0;36mGraphTransformer.forward\u001b[0;34m(self, x_in, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m x_in\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Compute edge scores\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py:90\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     88\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_log, valid_log = shared_training_loop(epoches, criterion, loader, vloader, model, lr, b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cf68b98a-e7f1-4b94-a8db-592d33e77212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(graph_data):\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "08c1bd1d-7f80-48db-a0aa-b13ffce4785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataload):\n",
    "    A, d = next(iter(dataload))\n",
    "    d = d.to(device)\n",
    "    out = model(d.x, d.edge_index, d.edge_attr, d.batch).detach().cpu().to_dense()\n",
    "    d = d.cpu()\n",
    "    #test_singularity(d.x), test_singularity(normalize_features(generate_random_helmholtz(500).toarray()))\n",
    "    \n",
    "    print(torch.norm(out.detach().cpu() @ A.float() - torch.eye(20), p=2))\n",
    "    print(torch.norm(out.detach().cpu() @ A.float(), p=2))\n",
    "    print(torch.norm(out.detach().cpu(), p=2))\n",
    "    print(torch.norm(torch.eye(20), p=2))\n",
    "    print(torch.linalg.det(out.to_dense().detach().cpu()))\n",
    "    print(torch.linalg.det(A.float()))\n",
    "    \n",
    "    print(torch.abs(torch.linalg.det(out.detach().cpu() @ A.float())))\n",
    "    print(torch.abs(torch.linalg.det(out.detach().cpu() @ A.float())))\n",
    "    plt.matshow(out.to_dense().detach().cpu())\n",
    "    plt.matshow(A[0])\n",
    "    plt.matshow(out.detach().cpu() @ A[0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c909a0e1-bf54-40c7-b035-b8a681025e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1452.3247)\n",
      "tensor(1452.3969)\n",
      "tensor(3.3735)\n",
      "tensor(4.4721)\n",
      "tensor(7.1423e-10)\n",
      "tensor([inf])\n",
      "tensor([inf])\n",
      "tensor([inf])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing(gtransformer, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b252b1a-a948-4965-b52f-28ed3c22b62b",
   "metadata": {},
   "source": [
    "## (Misc) Models\n",
    "\n",
    "Models I just had an idea with. Not sure if I will use this section, but its here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9723bc3-a72e-4283-99f4-53dbba1b4796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
